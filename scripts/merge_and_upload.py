#!/usr/bin/env python3
"""
å¹¶å‘å®‰å…¨çš„åˆå¹¶å’Œä¸Šä¼ è„šæœ¬

ç”¨äº GitHub Actionsï¼Œåœ¨ä¸Šä¼ åˆ° HF å‰å†æ¬¡åˆå¹¶æœ€æ–°æ•°æ®ï¼Œè§£å†³å¹¶å‘å†²çªã€‚

å·¥ä½œæµç¨‹ï¼š
1. è¯»å–ç”¨æˆ·æäº¤çš„ hf_data/ï¼ˆå¯èƒ½åŸºäºæ—§ç‰ˆæœ¬ HF æ•°æ®ï¼‰
2. ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå¯èƒ½å·²è¢«å…¶ä»–ç”¨æˆ·æ›´æ–°ï¼‰
3. ä¸‰æ–¹æ™ºèƒ½åˆå¹¶ï¼ˆä»¥ HF æœ€æ–°ç‰ˆæœ¬ä¸ºåŸºå‡†ï¼‰
4. ä¿å­˜åˆå¹¶ç»“æœï¼ˆä¾› upload_to_hf.py ä½¿ç”¨ï¼‰

è¿™æ ·å³ä½¿å¤šä¸ªç”¨æˆ·å¹¶å‘æäº¤ï¼Œä¹Ÿä¸ä¼šä¸¢å¤±æ•°æ®ã€‚
"""

from __future__ import annotations

import json
import urllib.request
from pathlib import Path

# HF é…ç½®
HF_REPO = "wangyao36/sagellm-benchmark-results"
HF_BRANCH = "main"


def download_from_hf(filename: str) -> list[dict]:
    """ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå…¬å¼€ï¼Œæ— éœ€ tokenï¼‰"""
    url = f"https://huggingface.co/datasets/{HF_REPO}/resolve/{HF_BRANCH}/{filename}"
    print(f"  ğŸ“¥ {url}")

    try:
        with urllib.request.urlopen(url, timeout=30) as response:
            data = json.loads(response.read().decode("utf-8"))
            print(f"    âœ“ {len(data)} æ¡è®°å½•")
            return data
    except urllib.error.HTTPError as e:
        if e.code == 404:
            print(f"    âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆé¦–æ¬¡ä¸Šä¼ ï¼‰")
        else:
            print(f"    âš ï¸ HTTP {e.code}: {e.reason}")
        return []
    except Exception as e:
        print(f"    âš ï¸ ä¸‹è½½å¤±è´¥: {e}")
        return []


def get_config_key(entry: dict) -> str:
    """
    ç”Ÿæˆé…ç½®å”¯ä¸€æ ‡è¯† key

    ç›¸åŒé…ç½® = ç›¸åŒç¡¬ä»¶ + ç›¸åŒæ¨¡å‹ + ç›¸åŒ workload + ç›¸åŒç²¾åº¦
    """
    hw = entry.get("hardware", {})
    model = entry.get("model", {})
    workload = entry.get("workload", {})
    cluster = entry.get("cluster")

    # æ„å»ºé…ç½® key
    parts = [
        hw.get("chip_model", "unknown"),
        str(hw.get("chip_count", 1)),
        model.get("name", "unknown"),
        model.get("precision", "FP16"),
        str(workload.get("input_length", 0)),
        str(workload.get("output_length", 0)),
    ]

    # å¦‚æœæ˜¯å¤šèŠ‚ç‚¹ï¼ŒåŠ å…¥èŠ‚ç‚¹ä¿¡æ¯
    if cluster and cluster.get("node_count", 1) > 1:
        parts.append(f"nodes_{cluster['node_count']}")

    return "|".join(parts)


def is_better_result(new_entry: dict, existing_entry: dict) -> bool:
    """
    åˆ¤æ–­æ–°ç»“æœæ˜¯å¦æ¯”ç°æœ‰ç»“æœæ›´å¥½

    è¯„åˆ¤æ ‡å‡†ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
    1. throughput_tps è¶Šé«˜è¶Šå¥½
    2. ttft_ms è¶Šä½è¶Šå¥½
    3. error_rate è¶Šä½è¶Šå¥½
    """
    new_metrics = new_entry.get("metrics", {})
    old_metrics = existing_entry.get("metrics", {})

    # throughput é«˜æ›´å¥½
    new_tps = new_metrics.get("throughput_tps", 0)
    old_tps = old_metrics.get("throughput_tps", 0)
    if new_tps > old_tps * 1.05:  # 5% å®¹å·®
        return True
    if old_tps > new_tps * 1.05:
        return False

    # ttft ä½æ›´å¥½
    new_ttft = new_metrics.get("ttft_ms", float("inf"))
    old_ttft = old_metrics.get("ttft_ms", float("inf"))
    if new_ttft < old_ttft * 0.95:  # 5% å®¹å·®
        return True
    if old_ttft < new_ttft * 0.95:
        return False

    # error_rate ä½æ›´å¥½
    new_err = new_metrics.get("error_rate", 1)
    old_err = old_metrics.get("error_rate", 1)
    if new_err < old_err:
        return True

    # é»˜è®¤ä¿ç•™ç°æœ‰çš„ï¼ˆä¸è¦†ç›–ï¼‰
    return False


def smart_merge(hf_latest: list[dict], user_data: list[dict]) -> list[dict]:
    """
    ä¸‰æ–¹æ™ºèƒ½åˆå¹¶

    å…³é”®è§„åˆ™ï¼š
    1. HF æœ€æ–°æ•°æ®ä¸ºåŸºå‡†ï¼ˆæƒå¨ç‰ˆæœ¬ï¼‰
    2. ç”¨æˆ·æ•°æ®è¿½åŠ æˆ–æ›´æ–°
    3. ç›¸åŒé…ç½®æ—¶ï¼Œé€‰æ‹©æ€§èƒ½æ›´å¥½çš„
    4. ä¸åŒé…ç½®åˆ™è¿½åŠ 

    è¿™æ ·å³ä½¿ç”¨æˆ·åŸºäºæ—§ç‰ˆæœ¬ HF æ•°æ®åˆå¹¶ï¼Œä¹Ÿèƒ½ä¸æœ€æ–°ç‰ˆæœ¬æ­£ç¡®åˆå¹¶ã€‚
    """
    merged: dict[str, dict] = {}

    # å…ˆåŠ å…¥ HF æœ€æ–°æ•°æ®ï¼ˆæƒå¨ç‰ˆæœ¬ï¼‰
    for entry in hf_latest:
        config_key = get_config_key(entry)
        merged[config_key] = entry

    added = 0
    updated = 0
    skipped = 0

    # åˆå¹¶ç”¨æˆ·æ•°æ®
    for entry in user_data:
        config_key = get_config_key(entry)

        if config_key not in merged:
            # æ–°é…ç½®ï¼Œç›´æ¥æ·»åŠ 
            merged[config_key] = entry
            added += 1
            print(f"    âœ“ æ–°å¢: {config_key[:60]}...")
        else:
            # å·²å­˜åœ¨ï¼Œæ¯”è¾ƒæ€§èƒ½
            if is_better_result(entry, merged[config_key]):
                merged[config_key] = entry
                updated += 1
                print(f"    â†‘ æ›´æ–°: {config_key[:60]}...")
            else:
                skipped += 1
                # ä¸æ‰“å°è·³è¿‡çš„ï¼ˆå¤ªå¤šï¼‰

    print(f"\n  ğŸ“Š åˆå¹¶ç»“æœ: æ–°å¢ {added}, æ›´æ–° {updated}, è·³è¿‡ {skipped}, æ€»è®¡ {len(merged)}")
    return list(merged.values())


def main():
    print("=" * 60)
    print("ğŸ”€ å¹¶å‘å®‰å…¨åˆå¹¶ï¼ˆGitHub Actionsï¼‰")
    print("=" * 60)

    # è·¯å¾„è®¾ç½®
    hf_data_dir = Path("hf_data")

    if not hf_data_dir.exists():
        print(f"\nâŒ hf_data/ ç›®å½•ä¸å­˜åœ¨")
        print("ğŸ’¡ ç”¨æˆ·åº”è¯¥å…ˆè¿è¡Œ 'sagellm-benchmark aggregate'")
        exit(1)

    # 1. è¯»å–ç”¨æˆ·æäº¤çš„æ•°æ®
    print("\nğŸ“‚ è¯»å–ç”¨æˆ·æäº¤çš„æ•°æ®...")
    user_single_file = hf_data_dir / "leaderboard_single.json"
    user_multi_file = hf_data_dir / "leaderboard_multi.json"

    if not user_single_file.exists() or not user_multi_file.exists():
        print(f"  âš ï¸ ç¼ºå°‘å¿…è¦æ–‡ä»¶")
        exit(1)

    user_single = json.loads(user_single_file.read_text(encoding="utf-8"))
    user_multi = json.loads(user_multi_file.read_text(encoding="utf-8"))
    print(f"  âœ“ Single: {len(user_single)} æ¡")
    print(f"  âœ“ Multi: {len(user_multi)} æ¡")

    # 2. ä» HF ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆå¯èƒ½å·²è¢«å…¶ä»–ç”¨æˆ·æ›´æ–°ï¼‰
    print("\nğŸ“¥ ä» Hugging Face ä¸‹è½½æœ€æ–°æ•°æ®...")
    hf_single = download_from_hf("leaderboard_single.json")
    hf_multi = download_from_hf("leaderboard_multi.json")

    # 3. æ™ºèƒ½åˆå¹¶
    print("\nğŸ”€ æ™ºèƒ½åˆå¹¶ï¼ˆè§£å†³å¹¶å‘å†²çªï¼‰...")
    print("\n  Single (å•æœº):")
    merged_single = smart_merge(hf_single, user_single)

    print("\n  Multi (å¤šæœº):")
    merged_multi = smart_merge(hf_multi, user_multi)

    # 4. ä¿å­˜åˆå¹¶ç»“æœï¼ˆè¦†ç›–ç”¨æˆ·æäº¤çš„ç‰ˆæœ¬ï¼‰
    print("\nğŸ’¾ ä¿å­˜åˆå¹¶ç»“æœ...")
    user_single_file.write_text(
        json.dumps(merged_single, indent=2, ensure_ascii=False), encoding="utf-8"
    )
    user_multi_file.write_text(
        json.dumps(merged_multi, indent=2, ensure_ascii=False), encoding="utf-8"
    )
    print(f"  âœ“ {user_single_file}")
    print(f"  âœ“ {user_multi_file}")

    print("\nâœ… å¹¶å‘å®‰å…¨åˆå¹¶å®Œæˆï¼")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥: è¿è¡Œ upload_to_hf.py ä¸Šä¼ åˆ° Hugging Face")


if __name__ == "__main__":
    main()
