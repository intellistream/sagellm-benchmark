name: Benchmark Regression

on:
  pull_request:
    branches: [main, main-dev]
    paths:
      - 'src/sagellm_benchmark/**'
      - 'scripts/compare_performance_baseline.py'
      - 'benchmark_baselines/**'
      - '.github/workflows/benchmark.yml'
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      update_baseline:
        description: 'Update baseline with current result'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    name: Benchmark (${{ github.event_name == 'release' && 'full' || 'light' }})
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]

      - name: Run benchmark (PR lightweight)
        if: github.event_name == 'pull_request'
        run: |
          mkdir -p benchmark_results
          sagellm-benchmark perf \
            --type e2e \
            --model sshleifer/tiny-gpt2 \
            --batch-size 1 \
            --precision fp16 \
            --max-output-tokens 8 \
            --output-json benchmark_results/perf_current.json \
            --output-markdown benchmark_results/perf_current.md

      - name: Run benchmark (release full)
        if: github.event_name == 'release'
        run: |
          mkdir -p benchmark_results
          sagellm-benchmark perf \
            --type e2e \
            --model sshleifer/tiny-gpt2 \
            --batch-size 1 --batch-size 4 --batch-size 8 \
            --precision fp16 --precision int8 \
            --max-output-tokens 16 \
            --output-json benchmark_results/perf_current.json \
            --output-markdown benchmark_results/perf_current.md

      - name: Compare with baseline
        id: compare
        run: |
          python scripts/compare_performance_baseline.py \
            --baseline benchmark_baselines/perf_baseline_e2e.json \
            --current benchmark_results/perf_current.json \
            --warning-threshold 5 \
            --critical-threshold 10 \
            --summary-json benchmark_results/perf_comparison_summary.json \
            --report-md benchmark_results/perf_comparison_report.md \
            --github-output "$GITHUB_OUTPUT"

      - name: Upload benchmark artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-regression-results
          path: |
            benchmark_results/perf_current.json
            benchmark_results/perf_current.md
            benchmark_results/perf_comparison_summary.json
            benchmark_results/perf_comparison_report.md

      - name: PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const status = `${{ steps.compare.outputs.overall_status }}`;
            const report = fs.readFileSync('benchmark_results/perf_comparison_report.md', 'utf8');
            const body = [
              '## ðŸ“Š Benchmark Regression Report',
              '',
              `Status: **${status.toUpperCase()}**`,
              '',
              report,
            ].join('\n');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });

      - name: Update baseline
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.update_baseline == 'true'
        run: |
          cp benchmark_results/perf_current.json benchmark_baselines/perf_baseline_e2e.json

      - name: Commit baseline update
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.update_baseline == 'true'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'chore(benchmark): update perf baseline'
          file_pattern: benchmark_baselines/perf_baseline_e2e.json

      - name: Fail on critical regression
        if: steps.compare.outputs.overall_status == 'critical'
        run: |
          echo "Critical performance regression detected (>10%)."
          exit 1
